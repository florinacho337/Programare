{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement a system which transform a text in a Markov chain and generate a saying or a poem in romanian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    translation_table = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translation_table)\n",
    "\n",
    "def build_markov_chain(text, order=3):\n",
    "    text = remove_punctuation(text)\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    chain = {}\n",
    "    for i in range(len(words) - order):\n",
    "        prefix = tuple(words[i:i+order])\n",
    "        suffix = words[i+order]\n",
    "        if prefix in chain:\n",
    "            chain[prefix].append(suffix)\n",
    "        else:\n",
    "            chain[prefix] = [suffix]\n",
    "    return chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem1(chain, rows=4):\n",
    "    random.seed(random.randint(0, 1000))\n",
    "    result = []\n",
    "    current_words = random.choice(list(chain.keys()))\n",
    "    for i in range(rows):\n",
    "        random.seed(random.randint(0, 1000))\n",
    "        # The first word of the row is capitalized\n",
    "        if i == 0:\n",
    "            while current_words[0][0].islower():\n",
    "                current_words = random.choice(list(chain.keys()))\n",
    "            # concatenate the current words to the result\n",
    "            result.extend(current_words)\n",
    "        next_word = random.choice(chain[current_words])\n",
    "        while next_word[0].islower():\n",
    "            result.append(next_word)\n",
    "            current_words = tuple(result[-len(current_words):])\n",
    "            next_word = random.choice(chain[current_words])\n",
    "        result.append(next_word)\n",
    "        current_words = tuple(result[-len(current_words):])\n",
    "    \n",
    "    # Add a newline after each line\n",
    "    for i in range(len(result) - 1):\n",
    "        if result[i+1][0].isupper():\n",
    "          result[i] += '\\n'\n",
    "    return ' '.join(result[:-1])\n",
    "\n",
    "def poetry_structure(poem, rows=4, words_per_row=6):\n",
    "    poem[0] = poem[0].capitalize()\n",
    "    for i in range(rows):\n",
    "        poem[(i+1)*words_per_row-1] += '\\n'\n",
    "        if (i+1)*words_per_row < len(poem):\n",
    "            poem[(i+1)*words_per_row] = poem[(i+1)*words_per_row].capitalize()\n",
    "\n",
    "def generate_poem2(chain, rows=4, words_per_row=6):\n",
    "    random.seed(random.randint(0, 1000))\n",
    "    current_words = random.choice(list(chain.keys()))\n",
    "    result = list(current_words)\n",
    "    for i in range(rows*words_per_row):\n",
    "        random.seed(random.randint(0, 1000))\n",
    "        next_word = random.choice(chain[current_words])\n",
    "        result.append(next_word)\n",
    "        current_words = tuple(result[-len(current_words):])\n",
    "    poetry_structure(result, rows, words_per_row)\n",
    "    return ' '.join(result) + '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate sayings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sayings(chain, words=6):\n",
    "    random.seed(random.randint(0, 1000))\n",
    "    current_words = random.choice(list(chain.keys()))\n",
    "    result = list(current_words)\n",
    "    for _ in range(words - len(current_words)):\n",
    "        next_word = random.choice(chain[current_words])\n",
    "        result.append(next_word)\n",
    "        current_words = tuple(result[-len(current_words):])\n",
    "    result[0] = result[0].capitalize()\n",
    "    return ' '.join(result) + '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poem:\n",
      "Pe negrele plăceri şiademenind lumina cu\n",
      " Îngeriiţi perfizi în iadul tău tragi\n",
      " Cerul şi astfel mil deschizi eu\n",
      " Nam fost niciodată ucenic dintrunceput deplin\n",
      " Maestru numa în.\n",
      "Sayings:\n",
      "Roade cine nu nici carne moale.\n",
      "Sacul lacomului nu ii ajunge oltu.\n",
      "Imi e baba rada ce imi.\n",
      "Bordeie atatea obiceie ce am avut.\n",
      "Se numara bobocii toate drumurile duc.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Read the text from data/corpus_complet.txt and build the Markov chain\n",
    "    with open('data/corpus_complet.txt') as f:\n",
    "        text = f.read()\n",
    "    chain = build_markov_chain(text, order=3)\n",
    "    # Generate a poem\n",
    "    poem = generate_poem2(chain)\n",
    "\n",
    "    print(\"Poem:\")\n",
    "    print(poem)\n",
    "    # Generate some sayings\n",
    "    with open('data/proverbe.txt') as f:\n",
    "        text = f.read()\n",
    "    chain = build_markov_chain(text, order=4)\n",
    "    print(\"Sayings:\")\n",
    "    for i in range(5):\n",
    "        print(generate_sayings(chain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. a.Generate a stanza of poetry in English language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: markovify in /home/florin/.local/lib/python3.10/site-packages (0.9.4)\n",
      "Requirement already satisfied: unidecode in /usr/local/lib/python3.10/dist-packages (from markovify) (1.3.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in /home/florin/.local/lib/python3.10/site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install markovify\n",
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poetry(model, rows=4):      \n",
    "    return '\\n'.join(model.make_sentence() for _ in range(rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Calculate the emotion of the generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/florin/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "def sentiment_analysis(text):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    return sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Replace randomly words with their synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/florin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/florin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def create_word2vec_model(text):\n",
    "    text = remove_punctuation(text.lower())\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    model = Word2Vec([tokens], min_count=1)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_synonyms(model, word, topn=5):\n",
    "    if word not in model.wv:\n",
    "        return []\n",
    "    synonyms = model.wv.most_similar(word, topn=topn)\n",
    "    return [syn[0] for syn in synonyms]\n",
    "\n",
    "def reconstruct_sentence(text):\n",
    "    reconstructed_sentence = \"\"\n",
    "    for i, token in enumerate(text):\n",
    "        if i > 0 and token[0] in string.punctuation:\n",
    "            reconstructed_sentence += token\n",
    "        else:\n",
    "            reconstructed_sentence += \" \" + token\n",
    "    return reconstructed_sentence.strip()\n",
    "    \n",
    "def replace_words(model, text):\n",
    "    result = []\n",
    "    for line in text.split('\\n'):\n",
    "        words_line = nltk.word_tokenize(line)\n",
    "        for i, word in enumerate(words_line):\n",
    "            random.seed(random.randint(0, 1000))\n",
    "\n",
    "            if random.randint(0, 50) > 40:\n",
    "                synonyms = get_synonyms(model, word)\n",
    "                if synonyms:\n",
    "                    words_line[i] = random.choice(synonyms)\n",
    "\n",
    "        result.append(reconstruct_sentence(words_line))\n",
    "    return '\\n'.join(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Calculate BLEU metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_bleu_score(reference_poems, generated_poem):\n",
    "    bleu_scores = []\n",
    "    for reference_poem in reference_poems:\n",
    "        bleu_score = nltk.translate.bleu_score.sentence_bleu([reference_poem], generated_poem)\n",
    "        bleu_scores.append(bleu_score)\n",
    "    \n",
    "    average_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
    "    return average_bleu_score, nltk.translate.bleu_score.sentence_bleu(reference_poems, generated_poem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poetry:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Make answer Muse: wilt thou be denied!\n",
      "Thy self away, art present still with thee shall stay.\n",
      "So shall those blots that do with me after I am now,\n",
      "Is perjured, murderous, bloody, full of your desire?\n",
      "And keep invention in a kind of praise;\n",
      "Say that thou teachest how to make love groan;\n",
      "Or if it do, not from my mistress reeks.\n",
      "Of bird, of flower, or shape which it fears to lose.\n",
      "Were't aught to me I am dead\n",
      "Thou art the grave and thee.\n",
      "\n",
      "Sentiment analysis:\n",
      "{'neg': 0.212, 'neu': 0.692, 'pos': 0.095, 'compound': -0.9097}\n",
      "\n",
      "Poetry after replacing words:\n",
      "Make haply Muse: wilt thee be hungry!\n",
      "Thy self art, art present still with love shall stay.\n",
      "So let those blots that do with me after I am now,\n",
      "Is perjured, suggest, bloody, full of your desire?\n",
      "And keep invention in a kind of praise;\n",
      "Say that art teachest how to make love groan;\n",
      "Or if it do, not from my mistress reeks.\n",
      "Of patient, of flower, or shape which it fears to lose.\n",
      "Were't aught to me I am dead\n",
      "Thou eyes the grave and thee.\n",
      "\n",
      "Bleu score:\n",
      "Average bleu score: 0.3161845254220881\n",
      "Bleu score: 0.8596468888492599\n"
     ]
    }
   ],
   "source": [
    "import markovify\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with open(\"data/shakespear.txt\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    poetry_model = markovify.NewlineText(text)\n",
    "\n",
    "    poetry = generate_poetry(poetry_model, rows=10)\n",
    "    print(\"Poetry:\")\n",
    "    print(poetry)\n",
    "    scores = sentiment_analysis(poetry)\n",
    "    print(\"\\nSentiment analysis:\")\n",
    "    print(scores)\n",
    "    print(\"\\nPoetry after replacing words:\")\n",
    "    model = create_word2vec_model(text)\n",
    "    poetry_with_synonyms = replace_words(model, poetry)\n",
    "    print(poetry_with_synonyms)\n",
    "    print(\"\\nBleu score:\")\n",
    "    text_without_punctuation = remove_punctuation(text)\n",
    "    reference_poems = text_without_punctuation.lower().split('\\n\\n')\n",
    "    avg_bleu_score, bleu_score = calculate_bleu_score(reference_poems, remove_punctuation(poetry).lower())\n",
    "    print(\"Average bleu score: \" + str(avg_bleu_score))\n",
    "    print(\"Bleu score: \" + str(bleu_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
